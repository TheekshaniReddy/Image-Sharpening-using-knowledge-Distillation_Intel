{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fI3zGpml1n-2",
        "outputId": "877ecfa4-7843-412d-a45f-b94445a2d3b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ GPU is active and ready! Device: Tesla T4\n"
          ]
        }
      ],
      "source": [
        "# ==============================================================================\n",
        "#                      CELL 1: SETUP & GPU CHECK (Corrected)\n",
        "# ==============================================================================\n",
        "# This cell imports libraries and verifies that a GPU is active.\n",
        "\n",
        "import os\n",
        "import io\n",
        "from collections import OrderedDict\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from google.colab import files\n",
        "from torchvision import transforms  # <-- THIS IS THE MISSING LINE TO ADD\n",
        "\n",
        "# --- Check for GPU ---\n",
        "# This line automatically selects the GPU if available, otherwise falls back to CPU.\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "  print(f\"‚úÖ GPU is active and ready! Device: {torch.cuda.get_device_name(0)}\")\n",
        "else:\n",
        "  print(\"‚ö†Ô∏è WARNING: No GPU detected. The live demo will be very slow.\")\n",
        "  print(\"Go to 'Runtime' -> 'Change runtime type' and select 'GPU' as the hardware accelerator.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "#               CELL 2: STUDENT MODEL ARCHITECTURE DEFINITION\n",
        "# ==============================================================================\n",
        "# This cell contains the Python classes that define the RRDBNet model structure.\n",
        "\n",
        "DOWNSCALE_FACTOR = 4\n",
        "\n",
        "class ResidualDenseBlock(nn.Module):\n",
        "    def __init__(self, nf=32, gc=16):\n",
        "        super(ResidualDenseBlock,self).__init__();self.conv1=nn.Conv2d(nf,gc,3,1,1);self.conv2=nn.Conv2d(nf+gc,gc,3,1,1);self.conv3=nn.Conv2d(nf+2*gc,gc,3,1,1);self.conv4=nn.Conv2d(nf+3*gc,gc,3,1,1);self.conv5=nn.Conv2d(nf+4*gc,nf,3,1,1);self.lrelu=nn.LeakyReLU(negative_slope=0.2,inplace=True)\n",
        "    def forward(self,x):\n",
        "        x1=self.lrelu(self.conv1(x));x2=self.lrelu(self.conv2(torch.cat((x,x1),1)));x3=self.lrelu(self.conv3(torch.cat((x,x1,x2),1)));x4=self.lrelu(self.conv4(torch.cat((x,x1,x2,x3),1)));x5=self.conv5(torch.cat((x,x1,x2,x3,x4),1));return x5*0.2+x\n",
        "\n",
        "class RRDB(nn.Module):\n",
        "    def __init__(self,nf,gc=16):\n",
        "        super(RRDB,self).__init__();self.RDB1=ResidualDenseBlock(nf,gc);self.RDB2=ResidualDenseBlock(nf,gc);self.RDB3=ResidualDenseBlock(nf,gc)\n",
        "    def forward(self,x):\n",
        "        out=self.RDB1(x);out=self.RDB2(out);out=self.RDB3(out);return out*0.2+x\n",
        "\n",
        "class RRDBNet_v9(nn.Module):\n",
        "    def __init__(self,in_nc=3,out_nc=3,nf=32,nb=4,gc=16,upscale=4):\n",
        "        super(RRDBNet_v9,self).__init__();self.conv_first=nn.Conv2d(in_nc,nf,3,1,1);self.body=nn.Sequential(*[RRDB(nf,gc=gc) for _ in range(nb)]);self.conv_body=nn.Conv2d(nf,nf,3,1,1);self.upsampler=nn.Sequential(nn.Upsample(scale_factor=2,mode='nearest'),nn.Conv2d(nf,nf,3,1,1),nn.LeakyReLU(0.2,inplace=True),nn.Upsample(scale_factor=2,mode='nearest'),nn.Conv2d(nf,nf,3,1,1),nn.LeakyReLU(0.2,inplace=True));self.conv_hr=nn.Conv2d(nf,nf,3,1,1);self.conv_last=nn.Conv2d(nf,out_nc,3,1,1);self.lrelu=nn.LeakyReLU(negative_slope=0.2,inplace=True)\n",
        "    def forward(self,x):\n",
        "        fea=self.conv_first(x);trunk=self.conv_body(self.body(fea));fea=fea+trunk;fea=self.upsampler(fea);fea=self.lrelu(self.conv_hr(fea));out=self.conv_last(fea);return torch.sigmoid(out)\n",
        "\n",
        "print(\"‚úÖ Student model architecture (RRDBNet_v9) defined.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2B_BKrMn139m",
        "outputId": "4f0ff013-ba61-4dda-eb25-7577f30b55d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Student model architecture (RRDBNet_v9) defined.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "#               CELL 3: LOAD THE TRAINED STUDENT MODEL\n",
        "# ==============================================================================\n",
        "# This cell instantiates the model and loads your trained .pth weights file.\n",
        "\n",
        "# Create an empty instance of the model and send it to the GPU\n",
        "model = RRDBNet_v9(nf=32, nb=4, gc=16, upscale=DOWNSCALE_FACTOR).to(DEVICE)\n",
        "\n",
        "print(\"Please upload your trained student model (.pth file).\")\n",
        "uploaded = files.upload()\n",
        "\n",
        "if not uploaded:\n",
        "    print(\"‚ùå Upload cancelled. Please run the cell again to upload the model.\")\n",
        "else:\n",
        "    try:\n",
        "        model_filename = list(uploaded.keys())[0]\n",
        "        model_data = uploaded[model_filename]\n",
        "\n",
        "        # Load the state dictionary from the uploaded file\n",
        "        state_dict = torch.load(io.BytesIO(model_data), map_location=DEVICE)\n",
        "\n",
        "        # This handles models that were trained with DataParallel (adds 'module.' prefix)\n",
        "        new_state_dict = OrderedDict()\n",
        "        for k, v in state_dict.items():\n",
        "            name = k[7:] if k.startswith('module.') else k\n",
        "            new_state_dict[name] = v\n",
        "\n",
        "        model.load_state_dict(new_state_dict)\n",
        "\n",
        "        # Set the model to evaluation mode. This is crucial for consistent results.\n",
        "        model.eval()\n",
        "\n",
        "        print(f\"‚úÖ Model '{model_filename}' loaded successfully and is ready for the demo.\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå FATAL ERROR loading model: {e}\")\n",
        "        print(\"Please ensure you uploaded the correct .pth file and that the architecture matches.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "yKwY6hTC18p5",
        "outputId": "4f93a1a4-57ad-4548-c4fd-422b1053b876"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please upload your trained student model (.pth file).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-1ed975ac-986f-4c00-9098-20b5baa74702\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-1ed975ac-986f-4c00-9098-20b5baa74702\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving best_v9_RRDB_model.pth to best_v9_RRDB_model (3).pth\n",
            "‚úÖ Model 'best_v9_RRDB_model (3).pth' loaded successfully and is ready for the demo.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "#      FINAL LIVE SIDE-BY-SIDE DEMO (Robust Single-Cell Version)\n",
        "# ==============================================================================\n",
        "# This single cell handles webcam initialization and the real-time enhancement\n",
        "# loop, displaying the original and enhanced feeds side-by-side.\n",
        "\n",
        "# --- Imports for this specific demo ---\n",
        "from IPython.display import display, Javascript, HTML\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode, b64encode\n",
        "import PIL\n",
        "import cv2\n",
        "import numpy as np\n",
        "import time\n",
        "from torchvision import transforms\n",
        "import io\n",
        "\n",
        "# We assume 'model', 'DEVICE', and other necessary variables exist from setup.\n",
        "# ------------------------------------------------------------------------------\n",
        "\n",
        "def pil_to_b64(pil_img):\n",
        "    \"\"\"Converts a PIL Image to a base64 encoded string for HTML display.\"\"\"\n",
        "    buffered = io.BytesIO()\n",
        "    pil_img.save(buffered, format=\"JPEG\")\n",
        "    return b64encode(buffered.getvalue()).decode('utf-8')\n",
        "\n",
        "def live_side_by_side_demo():\n",
        "    \"\"\"\n",
        "    Main function to run the entire live demo with side-by-side comparison.\n",
        "    \"\"\"\n",
        "    # --- 1. Define all necessary JavaScript and HTML ---\n",
        "    js_code = \"\"\"\n",
        "    var video;\n",
        "    var stream;\n",
        "\n",
        "    // Function to set up the HTML layout and start the camera\n",
        "    async function setupLayoutAndCamera() {\n",
        "      // Create hidden video element for capturing\n",
        "      video = document.createElement('video');\n",
        "      video.id = 'camera-video';\n",
        "      video.setAttribute('playsinline', '');\n",
        "      video.style.display = 'none';\n",
        "\n",
        "      // Attach the video to the document\n",
        "      const div = document.createElement('div');\n",
        "      div.appendChild(video);\n",
        "      document.body.appendChild(div);\n",
        "\n",
        "      // Start the stream\n",
        "      stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
        "      video.srcObject = stream;\n",
        "      await video.play();\n",
        "\n",
        "      return \"Camera is ready!\";\n",
        "    }\n",
        "\n",
        "    // Function to capture a single frame from the running stream\n",
        "    async function captureFrame() {\n",
        "      const canvas = document.createElement('canvas');\n",
        "      canvas.width = video.videoWidth;\n",
        "      canvas.height = video.videoHeight;\n",
        "      canvas.getContext('2d').drawImage(video, 0, 0);\n",
        "      return canvas.toDataURL('image/jpeg', 0.8);\n",
        "    }\n",
        "\n",
        "    // Function to update the side-by-side image elements\n",
        "    function updateImageViews(original_b64, enhanced_b64) {\n",
        "      document.getElementById('original-view').src = 'data:image/jpeg;base64,' + original_b64;\n",
        "      document.getElementById('enhanced-view').src = 'data:image/jpeg;base64,' + enhanced_b64;\n",
        "    }\n",
        "\n",
        "    // Function to stop the camera stream\n",
        "    function stopCamera() {\n",
        "      if (stream) {\n",
        "        stream.getTracks().forEach(track => track.stop());\n",
        "      }\n",
        "    }\n",
        "    \"\"\"\n",
        "    # --- Define the HTML structure for the side-by-side display ---\n",
        "    html_layout = \"\"\"\n",
        "    <div style=\"display: flex; justify-content: space-around;\">\n",
        "      <div style=\"text-align: center;\">\n",
        "        <h3>Original Feed</h3>\n",
        "        <img id=\"original-view\" width=\"480\">\n",
        "      </div>\n",
        "      <div style=\"text-align: center;\">\n",
        "        <h3>Enhanced Feed (w/ FPS)</h3>\n",
        "        <img id=\"enhanced-view\" width=\"480\">\n",
        "      </div>\n",
        "    </div>\n",
        "    \"\"\"\n",
        "\n",
        "    # --- 2. Inject JS/HTML and start the camera ---\n",
        "    display(HTML(html_layout))\n",
        "    display(Javascript(js_code))\n",
        "    print(\"Initializing webcam... Please allow camera access.\")\n",
        "    try:\n",
        "        eval_js('setupLayoutAndCamera()')\n",
        "        print(\"‚úÖ Webcam is active. Starting enhancement loop...\")\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Could not start camera. Error: {e}\")\n",
        "        return\n",
        "\n",
        "    # --- 3. Run the main enhancement loop ---\n",
        "    to_tensor = transforms.ToTensor()\n",
        "    to_pil = transforms.ToPILImage()\n",
        "    MODEL_INPUT_SIZE = (480, 270) # Width, Height\n",
        "\n",
        "    try:\n",
        "        while True:\n",
        "            # A. Capture a raw frame and convert it for display\n",
        "            b64_data_raw = eval_js('captureFrame()')\n",
        "            original_pil = PIL.Image.open(io.BytesIO(b64decode(b64_data_raw.split(',')[1])))\n",
        "            original_b64_display = pil_to_b64(original_pil) # For the left-side view\n",
        "\n",
        "            # B. Prepare the frame for the model\n",
        "            input_for_model_pil = original_pil.resize(MODEL_INPUT_SIZE, PIL.Image.BICUBIC)\n",
        "            input_tensor = to_tensor(input_for_model_pil).unsqueeze(0).to(DEVICE)\n",
        "\n",
        "            # C. Timed Inference\n",
        "            start_time = time.time()\n",
        "            with torch.no_grad():\n",
        "                output_tensor = model(input_tensor)\n",
        "            proc_time = time.time() - start_time\n",
        "            fps = 1.0 / proc_time\n",
        "\n",
        "            # D. Post-process, draw FPS text, and convert for display\n",
        "            # THE FIX IS HERE: The indentation is now correct.\n",
        "            enhanced_pil = to_pil(output_tensor.clamp(0, 1).squeeze(0).cpu())\n",
        "            enhanced_cv = cv2.cvtColor(np.array(enhanced_pil), cv2.COLOR_RGB2BGR)\n",
        "            cv2.putText(\n",
        "                enhanced_cv,\n",
        "                f\"Model FPS: {fps:.2f}\",\n",
        "                (20, 60), # Position adjusted for larger text\n",
        "                cv2.FONT_HERSHEY_SIMPLEX, 2, (0, 255, 0), 3 # Larger font\n",
        "            )\n",
        "            _, buffer = cv2.imencode('.jpg', enhanced_cv)\n",
        "            enhanced_b64_display = b64encode(buffer).decode('utf-8')\n",
        "\n",
        "            # E. Call JS to update both images at once\n",
        "            eval_js(f\"updateImageViews('{original_b64_display}', '{enhanced_b64_display}')\")\n",
        "\n",
        "    except KeyboardInterrupt:\n",
        "        print(\"\\nLoop stopped by user.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Loop stopped due to an error: {e}\")\n",
        "    finally:\n",
        "        # F. Clean up and stop the camera\n",
        "        print(\"Attempting to stop webcam stream...\")\n",
        "        eval_js('stopCamera()')\n",
        "        print(\"Webcam stream has been stopped.\")\n",
        "\n",
        "# --- Run the main demo function ---\n",
        "live_side_by_side_demo()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 526
        },
        "id": "NbDAZWeK2mQu",
        "outputId": "a4831893-f71f-4a41-f5e5-fbc3c88c2378"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div style=\"display: flex; justify-content: space-around;\">\n",
              "      <div style=\"text-align: center;\">\n",
              "        <h3>Original Feed</h3>\n",
              "        <img id=\"original-view\" width=\"480\">\n",
              "      </div>\n",
              "      <div style=\"text-align: center;\">\n",
              "        <h3>Enhanced Feed (w/ FPS)</h3>\n",
              "        <img id=\"enhanced-view\" width=\"480\">\n",
              "      </div>\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    var video;\n",
              "    var stream;\n",
              "\n",
              "    // Function to set up the HTML layout and start the camera\n",
              "    async function setupLayoutAndCamera() {\n",
              "      // Create hidden video element for capturing\n",
              "      video = document.createElement('video');\n",
              "      video.id = 'camera-video';\n",
              "      video.setAttribute('playsinline', '');\n",
              "      video.style.display = 'none';\n",
              "\n",
              "      // Attach the video to the document\n",
              "      const div = document.createElement('div');\n",
              "      div.appendChild(video);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      // Start the stream\n",
              "      stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
              "      video.srcObject = stream;\n",
              "      await video.play();\n",
              "\n",
              "      return \"Camera is ready!\";\n",
              "    }\n",
              "\n",
              "    // Function to capture a single frame from the running stream\n",
              "    async function captureFrame() {\n",
              "      const canvas = document.createElement('canvas');\n",
              "      canvas.width = video.videoWidth;\n",
              "      canvas.height = video.videoHeight;\n",
              "      canvas.getContext('2d').drawImage(video, 0, 0);\n",
              "      return canvas.toDataURL('image/jpeg', 0.8);\n",
              "    }\n",
              "\n",
              "    // Function to update the side-by-side image elements\n",
              "    function updateImageViews(original_b64, enhanced_b64) {\n",
              "      document.getElementById('original-view').src = 'data:image/jpeg;base64,' + original_b64;\n",
              "      document.getElementById('enhanced-view').src = 'data:image/jpeg;base64,' + enhanced_b64;\n",
              "    }\n",
              "\n",
              "    // Function to stop the camera stream\n",
              "    function stopCamera() {\n",
              "      if (stream) {\n",
              "        stream.getTracks().forEach(track => track.stop());\n",
              "      }\n",
              "    }\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initializing webcam... Please allow camera access.\n",
            "‚úÖ Webcam is active. Starting enhancement loop...\n",
            "\n",
            "Loop stopped by user.\n",
            "Attempting to stop webcam stream...\n",
            "Webcam stream has been stopped.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "#      FINAL LIVE SIDE-BY-SIDE DEMO (Dual FPS Measurement Version)\n",
        "# ==============================================================================\n",
        "# This version calculates and displays both the Model's pure speed and the\n",
        "# system's real-time end-to-end throughput.\n",
        "\n",
        "# --- Imports for this specific demo ---\n",
        "from IPython.display import display, Javascript, HTML\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode, b64encode\n",
        "import PIL\n",
        "import cv2\n",
        "import numpy as np\n",
        "import time\n",
        "from torchvision import transforms\n",
        "import io\n",
        "\n",
        "# We assume 'model', 'DEVICE', and other necessary variables exist from setup.\n",
        "# ------------------------------------------------------------------------------\n",
        "\n",
        "def pil_to_b64(pil_img):\n",
        "    \"\"\"Converts a PIL Image to a base64 encoded string for HTML display.\"\"\"\n",
        "    buffered = io.BytesIO()\n",
        "    pil_img.save(buffered, format=\"JPEG\")\n",
        "    return b64encode(buffered.getvalue()).decode('utf-8')\n",
        "\n",
        "def live_side_by_side_demo():\n",
        "    \"\"\"\n",
        "    Main function to run the entire live demo with side-by-side comparison.\n",
        "    \"\"\"\n",
        "    # --- 1. Define all necessary JavaScript and HTML ---\n",
        "    js_code = \"\"\"\n",
        "    var video;\n",
        "    var stream;\n",
        "    async function setupLayoutAndCamera() { /* ... JS code is the same ... */ }\n",
        "    async function captureFrame() { /* ... JS code is the same ... */ }\n",
        "    function updateImageViews(original_b64, enhanced_b64) { /* ... JS code is the same ... */ }\n",
        "    function stopCamera() { /* ... JS code is the same ... */ }\n",
        "    \"\"\"\n",
        "    # For brevity, I've collapsed the JS code. Use the full block from the previous answer.\n",
        "    # The full, correct JS code from the previous answer is used here.\n",
        "    js_code = \"\"\"\n",
        "    var video;\n",
        "    var stream;\n",
        "    async function setupLayoutAndCamera() { video = document.createElement('video'); video.id = 'camera-video'; video.setAttribute('playsinline', ''); video.style.display = 'none'; const div = document.createElement('div'); div.appendChild(video); document.body.appendChild(div); stream = await navigator.mediaDevices.getUserMedia({video: true}); video.srcObject = stream; await video.play(); return \"Camera is ready!\"; }\n",
        "    async function captureFrame() { const canvas = document.createElement('canvas'); canvas.width = video.videoWidth; canvas.height = video.videoHeight; canvas.getContext('2d').drawImage(video, 0, 0); return canvas.toDataURL('image/jpeg', 0.8); }\n",
        "    function updateImageViews(original_b64, enhanced_b64) { document.getElementById('original-view').src = 'data:image/jpeg;base64,' + original_b64; document.getElementById('enhanced-view').src = 'data:image/jpeg;base64,' + enhanced_b64; }\n",
        "    function stopCamera() { if (stream) { stream.getTracks().forEach(track => track.stop()); } }\n",
        "    \"\"\"\n",
        "\n",
        "    html_layout = \"\"\"\n",
        "    <div style=\"display: flex; justify-content: space-around;\">\n",
        "      <div style=\"text-align: center;\">\n",
        "        <h3>Original Feed</h3>\n",
        "        <img id=\"original-view\" width=\"480\">\n",
        "      </div>\n",
        "      <div style=\"text-align: center;\">\n",
        "        <h3>Enhanced Feed (w/ FPS)</h3>\n",
        "        <img id=\"enhanced-view\" width=\"480\">\n",
        "      </div>\n",
        "    </div>\n",
        "    \"\"\"\n",
        "\n",
        "    # --- 2. Inject JS/HTML and start the camera ---\n",
        "    display(HTML(html_layout))\n",
        "    display(Javascript(js_code))\n",
        "    print(\"Initializing webcam... Please allow camera access.\")\n",
        "    try:\n",
        "        eval_js('setupLayoutAndCamera()')\n",
        "        print(\"‚úÖ Webcam is active. Starting enhancement loop...\")\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Could not start camera. Error: {e}\")\n",
        "        return\n",
        "\n",
        "    # --- 3. Run the main enhancement loop ---\n",
        "    to_tensor = transforms.ToTensor()\n",
        "    to_pil = transforms.ToPILImage()\n",
        "    MODEL_INPUT_SIZE = (480, 270)  # Width, Height\n",
        "\n",
        "    try:\n",
        "        while True:\n",
        "            # === Start full loop timer ===\n",
        "            loop_start_time = time.time()\n",
        "\n",
        "            # === Capture and Prepare ===\n",
        "            b64_data_raw = eval_js('captureFrame()')\n",
        "            original_pil = PIL.Image.open(io.BytesIO(b64decode(b64_data_raw.split(',')[1])))\n",
        "            original_b64_display = pil_to_b64(original_pil)\n",
        "            input_for_model_pil = original_pil.resize(MODEL_INPUT_SIZE, PIL.Image.BICUBIC)\n",
        "            input_tensor = to_tensor(input_for_model_pil).unsqueeze(0).to(DEVICE)\n",
        "\n",
        "            # === Timed Model Inference ===\n",
        "            inference_start_time = time.time()\n",
        "            with torch.no_grad():\n",
        "                output_tensor = model(input_tensor)\n",
        "            inference_duration = time.time() - inference_start_time\n",
        "            model_fps = 1.0 / inference_duration\n",
        "\n",
        "            # === Post-process ===\n",
        "            enhanced_pil = to_pil(output_tensor.clamp(0, 1).squeeze(0).cpu())\n",
        "            enhanced_cv = cv2.cvtColor(np.array(enhanced_pil), cv2.COLOR_RGB2BGR)\n",
        "\n",
        "            # === Stop full loop timer and calculate Loop FPS ===\n",
        "            loop_duration = time.time() - loop_start_time\n",
        "            loop_fps = 1.0 / loop_duration\n",
        "\n",
        "            # === Overlay BOTH FPS text values ===\n",
        "            cv2.putText(\n",
        "                enhanced_cv,\n",
        "                f\"Model FPS: {model_fps:.2f}\", # The fast number\n",
        "                (20, 60),\n",
        "                cv2.FONT_HERSHEY_SIMPLEX, 2, (0, 255, 0), 3\n",
        "            )\n",
        "            cv2.putText(\n",
        "                enhanced_cv,\n",
        "                f\"System FPS: {loop_fps:.2f}\", # The \"realistic\" slow number\n",
        "                (20, 130),\n",
        "                cv2.FONT_HERSHEY_SIMPLEX, 2, (0, 100, 255), 3 # Different color\n",
        "            )\n",
        "\n",
        "            # === Convert and Update View ===\n",
        "            _, buffer = cv2.imencode('.jpg', enhanced_cv)\n",
        "            enhanced_b64_display = b64encode(buffer).decode('utf-8')\n",
        "            eval_js(f\"updateImageViews('{original_b64_display}', '{enhanced_b64_display}')\")\n",
        "\n",
        "    except KeyboardInterrupt:\n",
        "        print(\"\\nLoop stopped by user.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Loop stopped due to an error: {e}\")\n",
        "    finally:\n",
        "        print(\"Attempting to stop webcam stream...\")\n",
        "        eval_js('stopCamera()')\n",
        "        print(\"Webcam stream has been stopped.\")\n",
        "\n",
        "# --- Run the main demo function ---\n",
        "live_side_by_side_demo()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 526
        },
        "id": "HHjJeizLEaVs",
        "outputId": "155968eb-bb71-4375-b4aa-5825db584f50"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div style=\"display: flex; justify-content: space-around;\">\n",
              "      <div style=\"text-align: center;\">\n",
              "        <h3>Original Feed</h3>\n",
              "        <img id=\"original-view\" width=\"480\">\n",
              "      </div>\n",
              "      <div style=\"text-align: center;\">\n",
              "        <h3>Enhanced Feed (w/ FPS)</h3>\n",
              "        <img id=\"enhanced-view\" width=\"480\">\n",
              "      </div>\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    var video;\n",
              "    var stream;\n",
              "    async function setupLayoutAndCamera() { video = document.createElement('video'); video.id = 'camera-video'; video.setAttribute('playsinline', ''); video.style.display = 'none'; const div = document.createElement('div'); div.appendChild(video); document.body.appendChild(div); stream = await navigator.mediaDevices.getUserMedia({video: true}); video.srcObject = stream; await video.play(); return \"Camera is ready!\"; }\n",
              "    async function captureFrame() { const canvas = document.createElement('canvas'); canvas.width = video.videoWidth; canvas.height = video.videoHeight; canvas.getContext('2d').drawImage(video, 0, 0); return canvas.toDataURL('image/jpeg', 0.8); }\n",
              "    function updateImageViews(original_b64, enhanced_b64) { document.getElementById('original-view').src = 'data:image/jpeg;base64,' + original_b64; document.getElementById('enhanced-view').src = 'data:image/jpeg;base64,' + enhanced_b64; }\n",
              "    function stopCamera() { if (stream) { stream.getTracks().forEach(track => track.stop()); } }\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initializing webcam... Please allow camera access.\n",
            "‚úÖ Webcam is active. Starting enhancement loop...\n",
            "\n",
            "Loop stopped by user.\n",
            "Attempting to stop webcam stream...\n",
            "Webcam stream has been stopped.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "#      FINAL LIVE SIDE-BY-SIDE DEMO (Smoothed FPS Version)\n",
        "# ==============================================================================\n",
        "\n",
        "from IPython.display import display, Javascript, HTML\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode, b64encode\n",
        "import PIL\n",
        "import cv2\n",
        "import numpy as np\n",
        "import time\n",
        "from torchvision import transforms\n",
        "import io\n",
        "\n",
        "# We assume 'model', 'DEVICE', and other necessary variables exist from setup.\n",
        "# ------------------------------------------------------------------------------\n",
        "\n",
        "def pil_to_b64(pil_img):\n",
        "    \"\"\"Converts a PIL Image to a base64 encoded string for HTML display.\"\"\"\n",
        "    buffered = io.BytesIO()\n",
        "    pil_img.save(buffered, format=\"JPEG\")\n",
        "    return b64encode(buffered.getvalue()).decode('utf-8')\n",
        "\n",
        "def live_side_by_side_demo():\n",
        "    \"\"\"\n",
        "    Main function to run the entire live demo with side-by-side comparison\n",
        "    and smoothed FPS calculation.\n",
        "    \"\"\"\n",
        "    # --- 1. Define all necessary JavaScript and HTML ---\n",
        "    js_code = \"\"\"\n",
        "    var video;\n",
        "    var stream;\n",
        "    async function setupLayoutAndCamera() {\n",
        "      video = document.createElement('video');\n",
        "      video.id = 'camera-video';\n",
        "      video.setAttribute('playsinline', '');\n",
        "      video.style.display = 'none';\n",
        "      const div = document.createElement('div');\n",
        "      div.appendChild(video);\n",
        "      document.body.appendChild(div);\n",
        "      stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
        "      video.srcObject = stream;\n",
        "      await video.play();\n",
        "      return \"Camera is ready!\";\n",
        "    }\n",
        "    async function captureFrame() {\n",
        "      const canvas = document.createElement('canvas');\n",
        "      canvas.width = video.videoWidth;\n",
        "      canvas.height = video.videoHeight;\n",
        "      canvas.getContext('2d').drawImage(video, 0, 0);\n",
        "      return canvas.toDataURL('image/jpeg', 0.8);\n",
        "    }\n",
        "    function updateImageViews(original_b64, enhanced_b64) {\n",
        "      document.getElementById('original-view').src = 'data:image/jpeg;base64,' + original_b64;\n",
        "      document.getElementById('enhanced-view').src = 'data:image/jpeg;base64,' + enhanced_b64;\n",
        "    }\n",
        "    function stopCamera() {\n",
        "      if (stream) {\n",
        "        stream.getTracks().forEach(track => track.stop());\n",
        "      }\n",
        "    }\n",
        "    \"\"\"\n",
        "\n",
        "    html_layout = \"\"\"\n",
        "    <div style=\"display: flex; justify-content: space-around; align-items: center;\">\n",
        "      <div style=\"text-align: center;\">\n",
        "        <h3>Original Feed</h3>\n",
        "        <img id=\"original-view\" width=\"480\">\n",
        "      </div>\n",
        "      <div style=\"text-align: center;\">\n",
        "        <h3>Enhanced Feed (Model FPS + System FPS)</h3>\n",
        "        <img id=\"enhanced-view\" width=\"480\">\n",
        "      </div>\n",
        "    </div>\n",
        "    \"\"\"\n",
        "\n",
        "    # --- 2. Inject JS/HTML and start the camera (The CORRECT SINGLE method) ---\n",
        "    display(HTML(html_layout))\n",
        "    display(Javascript(js_code))\n",
        "    print(\"Initializing webcam... Please allow camera access.\")\n",
        "    try:\n",
        "        eval_js('setupLayoutAndCamera()')\n",
        "        print(\"‚úÖ Webcam is active. Starting real-time enhancement loop...\")\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Could not start camera. Error: {e}\")\n",
        "        return\n",
        "\n",
        "    # --- 3. Run the main enhancement loop ---\n",
        "    to_tensor = transforms.ToTensor()\n",
        "    to_pil = transforms.ToPILImage()\n",
        "    MODEL_INPUT_SIZE = (480, 270)\n",
        "\n",
        "    try:\n",
        "        # --- FPS TRACKING SETUP ---\n",
        "        frame_count = 0\n",
        "        fps_update_interval = 1.0  # Update the System FPS display every 1 second\n",
        "        last_fps_time = time.time()\n",
        "        smoothed_fps = 0\n",
        "\n",
        "        while True:\n",
        "            # A. Capture Frame\n",
        "            b64_data_raw = eval_js('captureFrame()')\n",
        "            original_pil = PIL.Image.open(io.BytesIO(b64decode(b64_data_raw.split(',')[1])))\n",
        "\n",
        "            # B. Preprocess (FIX #2: Add PIL.Image.BICUBIC)\n",
        "            input_tensor = to_tensor(original_pil.resize(MODEL_INPUT_SIZE, PIL.Image.BICUBIC)).unsqueeze(0).to(DEVICE)\n",
        "\n",
        "            # C. Model Inference + Model FPS Timing\n",
        "            model_start = time.time()\n",
        "            with torch.no_grad():\n",
        "                output_tensor = model(input_tensor)\n",
        "            model_time = time.time() - model_start\n",
        "            model_fps = 1.0 / model_time if model_time > 0 else 0\n",
        "\n",
        "            # D. Postprocess\n",
        "            enhanced_pil = to_pil(output_tensor.clamp(0, 1).squeeze(0).cpu())\n",
        "            enhanced_cv = cv2.cvtColor(np.array(enhanced_pil), cv2.COLOR_RGB2BGR)\n",
        "\n",
        "            # E. Rolling FPS Update\n",
        "            frame_count += 1\n",
        "            current_time = time.time()\n",
        "            if current_time - last_fps_time >= fps_update_interval:\n",
        "                smoothed_fps = frame_count / (current_time - last_fps_time)\n",
        "                last_fps_time = current_time\n",
        "                frame_count = 0\n",
        "\n",
        "            # F. Overlay both FPS on output\n",
        "            cv2.putText(enhanced_cv, f\"Model FPS: {model_fps:.2f}\", (20, 60),\n",
        "                        cv2.FONT_HERSHEY_SIMPLEX, 1.5, (0, 255, 0), 3)\n",
        "            cv2.putText(enhanced_cv, f\"System FPS: {smoothed_fps:.2f}\", (20, 110),\n",
        "                        cv2.FONT_HERSHEY_SIMPLEX, 1.5, (0, 140, 255), 3)\n",
        "\n",
        "            # G. Update display\n",
        "            _, buffer = cv2.imencode('.jpg', enhanced_cv)\n",
        "            enhanced_b64_display = b64encode(buffer).decode('utf-8')\n",
        "            original_b64_display = pil_to_b64(original_pil)\n",
        "\n",
        "            eval_js(f\"updateImageViews('{original_b64_display}', '{enhanced_b64_display}')\")\n",
        "\n",
        "    except KeyboardInterrupt:\n",
        "        print(\"\\n‚èπÔ∏è Loop stopped by user.\")\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Loop stopped due to error: {e}\")\n",
        "    finally:\n",
        "        # H. Clean up and stop the camera\n",
        "        print(\"Attempting to stop webcam stream...\")\n",
        "        eval_js('stopCamera()')\n",
        "        print(\"üõë Webcam stream has been stopped.\")\n",
        "\n",
        "\n",
        "# --- FIX #3: Call the main function to run it ---\n",
        "live_side_by_side_demo()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 526
        },
        "id": "fuXdU5sTOWEt",
        "outputId": "255185d9-0c24-478e-e842-af343603bae2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div style=\"display: flex; justify-content: space-around; align-items: center;\">\n",
              "      <div style=\"text-align: center;\">\n",
              "        <h3>Original Feed</h3>\n",
              "        <img id=\"original-view\" width=\"480\">\n",
              "      </div>\n",
              "      <div style=\"text-align: center;\">\n",
              "        <h3>Enhanced Feed (Model FPS + System FPS)</h3>\n",
              "        <img id=\"enhanced-view\" width=\"480\">\n",
              "      </div>\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    var video;\n",
              "    var stream;\n",
              "    async function setupLayoutAndCamera() {\n",
              "      video = document.createElement('video');\n",
              "      video.id = 'camera-video';\n",
              "      video.setAttribute('playsinline', '');\n",
              "      video.style.display = 'none';\n",
              "      const div = document.createElement('div');\n",
              "      div.appendChild(video);\n",
              "      document.body.appendChild(div);\n",
              "      stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
              "      video.srcObject = stream;\n",
              "      await video.play();\n",
              "      return \"Camera is ready!\";\n",
              "    }\n",
              "    async function captureFrame() {\n",
              "      const canvas = document.createElement('canvas');\n",
              "      canvas.width = video.videoWidth;\n",
              "      canvas.height = video.videoHeight;\n",
              "      canvas.getContext('2d').drawImage(video, 0, 0);\n",
              "      return canvas.toDataURL('image/jpeg', 0.8);\n",
              "    }\n",
              "    function updateImageViews(original_b64, enhanced_b64) {\n",
              "      document.getElementById('original-view').src = 'data:image/jpeg;base64,' + original_b64;\n",
              "      document.getElementById('enhanced-view').src = 'data:image/jpeg;base64,' + enhanced_b64;\n",
              "    }\n",
              "    function stopCamera() {\n",
              "      if (stream) {\n",
              "        stream.getTracks().forEach(track => track.stop());\n",
              "      }\n",
              "    }\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initializing webcam... Please allow camera access.\n",
            "‚úÖ Webcam is active. Starting real-time enhancement loop...\n",
            "\n",
            "‚èπÔ∏è Loop stopped by user.\n",
            "Attempting to stop webcam stream...\n",
            "üõë Webcam stream has been stopped.\n"
          ]
        }
      ]
    }
  ]
}